TODO
- controlla sezione "da validare"
- creare classe Fault e altra classe che "implementa" la coppia per migliorare
  la leggibilita'
    - ok
- cambia firstState in initialState dentro ManagementProtocol
    - ok
- mappa di mappe per rappresentare i binding
    - per ora no, ok
- refactoring degli assert e nomi campi 
    - ok
- definire opportune eccezioni per op fallite o non fattibili
- applicare licenza apache 2.0
- implementare operazioni offerte all'analyzer (op_start, ...)
    - ok
- metodi per il ritorno dei fault
    - ok
- implementare metodo "getPossibleTransition"
    - ok
- sistemare commenti in modo corente
    - ok
- correzione "istance" e "bond" in Instance e Binding
    - ok
- definire funzione "higher order" per la funzione pi e definire una pi di defualt
    - quella di default la facciamo tipo "load balancer"
    > per il momento ho implementato una pi naive che torna la prima NodeInstance capace di
      soddifare il requirement
        - ok
- metti un po' di coerenza nel naming dei parametri, variabili di supporto ecc. 


NOTE
1) Binding: id nodo n -> lista dei Binding del tipo <requirement di n, nodo n1 che soddisfa r di n>

2) rappresentare i binding come Map<String, Map<Requirement, String>> secondo 
   me potrebbe peggiorare di molto la leggibilita'. 
   Ad esempio, nel metodo getSatisfiedReq(NodeIstance n) devo tornare la lista
   di requirement di n che sono soddisfatti. 
   In questo modo pero' ho bisogno dei requirement da usare come chiave per 
   la seconda mappa. 
   Quindi dovrei andare a prendermi tutti i requirement necessari in quello stato, e
   per ogni requirement, usare la mappa.
   Il vantaggio presazionale si ha in base a quanti requirement un singolo nodo ha
   (la mia implementazione costa n, c'e' una lista). a questo punto la scelta
   dipende dagli obiettivi della libreria, se vuole essere super generale, in modo
   da venire potenzialmente usata in applicazioni in cui ci sono moltissimi nodi
   (molti dei quali hanno decine di requirement) scrivo la map di map, 
   altrimenti il tradeoff leggibilita'/efficienza potrebbe non convenire (?) 

Da validare
- un'operazione avra' sempre quel set di reqs (esempio config, che parte da due stati diversi) ?
    - per ora assumo di si

RICORDA 

tu vuoi fare un op: prendi quella operazione e cerchi la relativa transizione. E' LA TRANSIZIONE A RICHIEDERE REQS
- devi modificare la factory mettendo i requirement delle transizioni 
    - tipo op install: not-installed -> install -> installed ha i seguenti reqs, quindi in rho ci deve essere la coppia <not-installedinstallinstalled, reqs>
        - io sparo l'o, il codice si prende la transizione per quell'op e ragione sui reqs necessari 

- a questo punto pero' sarebbe meglio organizzare le transizioni come una mappa: <op, transizioni di quella op> (che magari partono da roba diversa)
    - piu' efficiente

Importanti
- c'era un problema sui fault. Siccome in opEnd non controllavamo i fault causati dai containment req non veniva lanciata nessuna 
  eccezione quando eseguivo "install" su backend, nonostante questo richieda "host" a node (il binding c'e' ma node non era nello stato giusto, 
  situazione di testing). Ho quindi 
    - modificato opEnd per testare anche errori di containment (brokenInstances)
    - modificato isBrokenInstance: prima controllava solo che il container fosse attivo (dentro il G set), ora controllo anche che 
      in questo momento stia offrendo la giusta cap
        - questo forse va contro la tesi ma non vedo come altro verificare che il requisito di containment valga

        - NO, pending faults sbagliato. il caso in cui host non e' offerto e' un pending fault, broken instance e' SOLO quando il container
          mi crepa e mi ammazza anche l'istanza sopra. aggiusta

- problema con removeAll
    - siccome funziona con i ref mi sovrascrive il protocollo. esempio: nel metodo addNewBindings faccio neededReqs.removeAll(satisfiedReqs)
      cosi da ottenere la lista di requisiti necessari ma non soddisfatti
        - questo pero' e' problematico: neededReqs viene direttamente dall'automa (mentre satisfiedReqs e' calcolato dal global state), questo 
          significa che se "host" e' sia needed che satisfied io perdo "host" nell'automa (perdo l'associazione in rho: stato/transizione -> host)
        - non uso piu' removeAll
        > ho rimosso tutti i removeAll

- la storia dei reqs di containment continua ad essere strana. quando instanceOfBackend e' nello stato available tecnicamente non richiede nulla
  eppure ha un reqs soddisfatto (ovvero host, containmenet req offerto da node). La confusione e' solo concettuale in quanto tutti i metodi 
  che aggiornano i runtime binding non toccano i requirement di containment (quindi in pratica la roba funziona, i runtime binding di containment sono
  gestiti esplicitamente) ma questi runtime binding "invisibili" potrebbero essere poco comprensibili

- aggiunto controllo != null capableInstance su addNewbindings (globalSTate)


